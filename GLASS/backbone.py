import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.models import resnet50
from torchvision.ops import FeaturePyramidNetwork
from collections import OrderedDict

class GLASSBackbone(nn.Module):
    def __init__(self, pretrained=True, fpn_out_channels=256):
        """
        Args: pretrained (bool): If True, load pre-trained ResNet50 weights.
              fpn_out_channels (int): The number of output channels for each FPN level.
        """
        super(GLASSBackbone, self).__init__()
        
        resnet = resnet50(weights='IMAGENET1K_V1' if pretrained else None)
        
        # Extract individual layers for fine-grained control
        self.conv1 = resnet.conv1
        self.bn1 = resnet.bn1
        self.relu = resnet.relu
        self.maxpool = resnet.maxpool
        
        # ResNet stages (corresponding to C2, C3, C4, C5 in FPN terminology)
        self.layer1 = resnet.layer1  # Output channels: 256 (for C2)
        self.layer2 = resnet.layer2  # Output channels: 512 (for C3)
        self.layer3 = resnet.layer3  # Output channels: 1024 (for C4)
        self.layer4 = resnet.layer4  # Output channels: 2048 (for C5)
        
        # PyTorch's built-in FPN
        # Input channels for FPN come from ResNet C2, C3, C4, C5 outputs
        self.fpn = FeaturePyramidNetwork(
            in_channels_list=[256, 512, 1024, 2048],  # Corresponding to ResNet layer1 to layer4 outputs
            out_channels=fpn_out_channels
        )
        
        # Additional convolutions to generate P6 and P7 feature levels
        # P6 is derived from P5 (highest FPN level) by strided convolution
        # P7 is derived from P6 by another strided convolution
        self.p6_conv = nn.Conv2d(fpn_out_channels, fpn_out_channels, kernel_size=3, stride=2, padding=1)
        self.p7_conv = nn.Conv2d(fpn_out_channels, fpn_out_channels, kernel_size=3, stride=2, padding=1)
        
    def forward(self, x):
        """
        Args: x (torch.Tensor): Input tensor of shape (B, 3, H, W).
        
        Returns: list[torch.Tensor]: A list of feature maps at different scales (P2, P3, P4, P5, P6, P7).
        """
        # ResNet backbone feature extraction
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        c1 = self.maxpool(x)
        
        c2 = self.layer1(c1)  # Output of ResNet layer1 (corresponding to C2 feature map)
        c3 = self.layer2(c2)  # Output of ResNet layer2 (corresponding to C3 feature map)
        c4 = self.layer3(c3)  # Output of ResNet layer3 (corresponding to C4 feature map)
        c5 = self.layer4(c4)  # Output of ResNet layer4 (corresponding to C5 feature map)
        
        # Prepare input for FPN - it expects an OrderedDict
        fpn_input = OrderedDict([
            ('feat0', c2),  # P2 level
            ('feat1', c3),  # P3 level
            ('feat2', c4),  # P4 level
            ('feat3', c5),  # P5 level
        ])
        
        # Apply built-in FPN to get P2, P3, P4, P5
        fpn_output = self.fpn(fpn_input)
        
        # Extract features in the correct order (P2, P3, P4, P5)
        # PyTorch FPN returns an OrderedDict with the same keys as input
        fpn_features = [
            fpn_output['feat0'],  # P2
            fpn_output['feat1'],  # P3
            fpn_output['feat2'],  # P4
            fpn_output['feat3'],  # P5
        ]
        
        # Generate P6 and P7 feature levels
        # P6 is generated by applying a 3x3 stride-2 conv on P5
        p6 = self.p6_conv(fpn_features[-1])  # fpn_features[-1] is P5
        
        # P7 is generated by applying a 3x3 stride-2 conv on P6
        p7 = self.p7_conv(p6)
        
        # Combine all feature maps: P2, P3, P4, P5, P6, P7
        fpn_features.extend([p6, p7])
        
        return fpn_features
